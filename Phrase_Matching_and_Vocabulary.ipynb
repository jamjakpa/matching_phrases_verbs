{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phrase Matching and Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#rule based matching tool called 'matcher' and that allows you to build a library of token patterns.\n",
    "#then match those patterns against a doc object, to return a list of found matches.\n",
    "#and you can match actually every part of the token including text and annotations and you can add mutiple patterns\n",
    "#to the same matcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the matcher library\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating matcher object\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we need to create patterns that we actually want to match on. you have a list and creating dictionary in these list\n",
    "#the first Pattern I look for SolarPower or Solar-power or Solar power, I try to detect all three patterns\n",
    "#the second pattern we are looking forsome sort of puctuation like a dash in the middle and boolean True\n",
    "#then we pass in the dictionary with lower as a key and then is the lowercase equal to power\n",
    "#the third pattern is lower equal to solar and then is the token immediatiately following this is that the string power\n",
    "# SolarPower\n",
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "# Solar-power\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True},{'LOWER':'power'}]\n",
    "# Solar power\n",
    "pattern3 = [{'LOWER':'solar'},{'LOWER':'power'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have these 3 Patterns and now its time to add them to my matcher and we name our matcher 'Solarpower' matcher\n",
    "#callbacks 'None'\n",
    "#so now these three particular patterns have been added to this matching object and they run under the 'SolarPower'\n",
    "matcher.add('SolarPower',None,pattern1,pattern2,pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So now that we have this solar power matcher Let's go ahead and create a document and see if we're able to match on these\n",
    "#various phrases.\n",
    "doc = nlp(u\"The Solar Power industry continues to grow a solarpower increases. Solar-power is amazing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we take the matcher that i have created and then pass in that doc that document object.\n",
    "#And i will set a variable called found matches Equal to this matcher object\n",
    "found_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 8, 9), (8656102463236116519, 11, 14)]\n"
     ]
    }
   ],
   "source": [
    "#what is nice here is I can simply print out my found that matches and its to return back tuples with three pieces of\n",
    "#information\n",
    "#The first piece of information (8656102463236116519 is the match ID essentially the string ID for the particular match\n",
    "#and then it indicates the start '1' and the stop '3' the start and the stop is really on the token \n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 3 Solar Power\n",
      "8656102463236116519 SolarPower 8 9 solarpower\n",
      "8656102463236116519 SolarPower 11 14 Solar-power\n"
     ]
    }
   ],
   "source": [
    "# i create a little for loop that prints out these strings representation\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "    span = doc[start:end]                    # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is how you remove a particular pattern you have just created, lets say you no longer were interested in this SolarPower\n",
    "#matcher and any of these old patterns anymore, you wanted a full update instead of adding o the matcher.\n",
    "#instead of adding to the matcher , you can remove from the matcher by doing this\n",
    "#matcher.remove('SolarPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now you can make token rules optional by passing and O.P. Asterix argument.So that lets us streamline our patterns list.\n",
    "#I create a new set of patterns , we have removed the old set of pattern \"SolarPower\"\n",
    "#let's create a new set\n",
    "#i put an asterix for a string. it allows me with this pattern to match zero or more times.\n",
    "# pattern1 is going to be able ro find solarpower SolarPower put together as lowercase\n",
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "#pattern2 graps solar.power and any amount of punctuation thats what the Asterix is doing with the O.P. so it can be double \n",
    "#dahses or can be one underscore or -- + . or whatever it happens to be punctuation an then power\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True,'OP':'*'},{'LOWER':'power'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower',None,pattern1,pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so let's add thatas our new solar power matching and let's create a new document doc\n",
    "doc2 = nlp(u\"Solar--power is solarpower yay!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 0, 3), (8656102463236116519, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how i created my own patterns and match on them by using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
